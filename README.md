# parse27k_tools
Tools for the Parse-27k Dataset - evaluation routines and some simple scripts to get started...

Find the dataset here:
[http://www.vision.rwth-aachen.de/parse27k]

## Installation & Requirements
We use Python 2.7 on a 64-bit Linux -- but the tools might run on other platforms as well.

The tools have some dependencies. If you are using Python regularly for scientific computing, 
all of this is likely installed already. Otherwise they can all be easily obtained through `pip`.

These tools depend on:
```
argparse
futures
h5py
Pillow
skimage
matplotlib
numpy
```

If you have never used Python before, install Python 2.7 on your system. Then follow these commands:
```
virtualenv new_environment
source new_environment/bin/activate
pip install numpy
pip install scipy
pip install skimage
pip install -r requirements.txt
```
*Note* for some reason, it only worked for me to install `numpy`,`scipy`, and `skimage` separately.
With the above workaround, it works smoothly for me.

## Usage
You can run the scripts with option `-h` for a basic description of their parameters.
The basic functions are:

* `preprocess_dataset.py`: create crops from the full images and store in `HDF5` file.
* `parse_evaluation.py`: compute performance measures from predictions.
* `visualize_crops.py`: visualize examples from a file generated by `preprocess_dataset.py`.
* `visualize_pid.py`: visualize a specific *pedestrianID* from an `HDF5` file generated by `preprocess_dataset.py`. The *pedestrianID* is a unique identifier for the examples within the dataset.

## Preprocessing the Dataset
As an example of how to use the dataset, this package includes `preprocess_dataset.py`.
This will read the annotations from the database, crop the examples from the original images, and
store the result in an `HDF5` file.
The resulting file will have two *datasets* (as it is called in `HDF5` language): `crops` and `labels`.
The `labels` is a *NxK* matrix, for *N* examples and *K* attributes.
The meaning is encoded in the `names` attribute.

```
$ export PARSE_PATH=_where_you_saved_the_dataset_
$ ./preprocess_dataset.py --output_dir /tmp/crops --padding_mode zero --padding 32
$ ./visualize_crops.py -r /tmp/crops/train.hdf5
```
## Evaluation Modes
The tool `parse_evaluation.py` allows to modes of evaluation - *retrieval* and *classification*.
See [our paper](http://www.vision.rwth-aachen.de/publications/pdf/parse-acn-iccv2015) for details on the difference.

The tool expects the predictions in an `HDF5`-file, with one *dataset* for each attribute.
For an example look at: *random_predictions.hdf5*

```
$ ./parse_evaluation.py /tmp/crops/test.hdf5 ./random_predictions.hdf5
```
## Bugs & Problems & Updates
If you are working with the *Parse-27k* dataset, we encourage you to follow this repository.
In case there are any bug-fixes or changes to the evaluation pipeline, GitHub will let you know.

